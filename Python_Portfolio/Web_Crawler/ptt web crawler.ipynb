{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PTT is a popular online forum in Taiwan. Based on the number of replies of each article, if the number is over 50, the specific article would be called a popular article. The code is to find today's popular articles in specific topic and store them into a json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.ptt.cc'\n",
    "topic = 'NBA' #there are different kinds of topics on ptt\n",
    "url = URL + '/bbs/'+ topic + '/index.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def get_resource(url):\n",
    "    headers = {\"user-agent\":\"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; AcooBrowser; .NET CLR 1.1.4322; .NET CLR 2.0.50727)\"}\n",
    "    return requests.get(url, headers=headers, cookies={'over18':'1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_html(r):\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        r.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(r.text,'lxml')\n",
    "    else:\n",
    "        print('error')\n",
    "        soup = None\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def web_scraping_bot(url):\n",
    "    articles = []\n",
    "    soup = parse_html(get_resource(url))\n",
    "    if soup:\n",
    "        today = time.strftime('%m/%d').lstrip('0') #get today's date and left strip 0 to fit the ptt date format\n",
    "        current_articles, prev_url = get_articles(soup, today)\n",
    "        while current_articles: #if we can get current_articles, we keep finding whether there are also today's articles in previous page\n",
    "            articles = articles+current_articles\n",
    "            print('wait two seconds...')\n",
    "            time.sleep(2)\n",
    "            soup = parse_html(get_resource(URL + prev_url))\n",
    "            current_articles, prev_url = get_articles(soup, today)\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles(soup, date):\n",
    "    articles = []\n",
    "    #get previous page url\n",
    "    tag_div = soup.find('div',class_='btn-group btn-group-paging')\n",
    "    tag_a = tag_div.find_all('a',class_='btn wide')\n",
    "    prev_url = tag_a[1]['href']\n",
    "    \n",
    "    tag_divs = soup.find_all('div',class_='r-ent')\n",
    "    for tag in tag_divs:\n",
    "        if tag.find('div',class_='date').text.strip() == date:#only include today's articles\n",
    "            push_count = 0\n",
    "            push_str = tag.find('div',class_='nrec').text\n",
    "            #get the number of replies\n",
    "            if push_str: \n",
    "                try:\n",
    "                    push_count = int(push_str)\n",
    "                except ValueError: #if push_str is not number (爆,X1,X2)\n",
    "                    if push_str == '爆':\n",
    "                        push_count = 99\n",
    "                    elif push_str.startswith('X'):\n",
    "                        push_count = -10\n",
    "            #get title, href, author of the article\n",
    "            if tag.find('a'): #if we can find url, it means the article is still exist, not being removed\n",
    "                href = tag.find('a')['href']\n",
    "                title = tag.find('a').text\n",
    "                author = tag.find('div',class_='author').text\n",
    "                articles.append({\n",
    "                    'title':title,\n",
    "                    'href':href,\n",
    "                    'push_count':push_count,\n",
    "                    'author':author\n",
    "                })\n",
    "    return articles, prev_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular_articles(articles):\n",
    "    return [item for item in articles if item['push_count']>=50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_to_json(articles, file):\n",
    "    with open(file,'w',encoding='utf-8') as fp:\n",
    "        json.dump(popular_articles, fp, indent=2, sort_keys=True, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait two seconds...\n",
      "wait two seconds...\n",
      "wait two seconds...\n",
      "{'title': '[情報] NBA Standings (Nov. 30, 2022)', 'href': '/bbs/NBA/M.1669793303.A.894.html', 'push_count': 2, 'author': 'guardyo'}\n",
      "{'title': '[Live] 勇士 @ 獨行俠', 'href': '/bbs/NBA/M.1669766565.A.54B.html', 'push_count': 99, 'author': 'pneumo'}\n",
      "{'title': '[花邊] 咖哩、唐西奇賽前半場三分表演', 'href': '/bbs/NBA/M.1669767680.A.C06.html', 'push_count': 27, 'author': 'ckpioneer'}\n",
      "{'title': '[情報] Ben Simmons 膝蓋痠痛 將缺席明天比賽', 'href': '/bbs/NBA/M.1669768223.A.215.html', 'push_count': 20, 'author': 'thnlkj0665'}\n",
      "{'title': '[BOX ] Knicks 140:110 Pistons 數據', 'href': '/bbs/NBA/M.1669774529.A.7C9.html', 'push_count': 16, 'author': 'Rambo'}\n",
      "{'title': '[花邊] 反串網黑開嘲諷 KD: 你需要休息一下了', 'href': '/bbs/NBA/M.1669774944.A.8D8.html', 'push_count': 34, 'author': 'pneumo'}\n",
      "{'title': '[情報] 老巴：小牛這樣打是拿不到冠軍的', 'href': '/bbs/NBA/M.1669775788.A.1E5.html', 'push_count': 99, 'author': 'pneumo'}\n",
      "{'title': '[Live] 快艇 @ 拓荒者', 'href': '/bbs/NBA/M.1669777542.A.A57.html', 'push_count': 89, 'author': 'pneumo'}\n",
      "{'title': '[BOX ] Warriors 113:116 Mavericks 數據', 'href': '/bbs/NBA/M.1669777622.A.1BC.html', 'push_count': 99, 'author': 'Rambo'}\n",
      "{'title': '[花邊] 老巴保證活塞會贏 結果', 'href': '/bbs/NBA/M.1669778102.A.79C.html', 'push_count': 49, 'author': 'Skyblueway'}\n",
      "{'title': '[情報] 最後10秒時，Curry被吹走步', 'href': '/bbs/NBA/M.1669778178.A.954.html', 'push_count': 99, 'author': 'usnavyseal'}\n",
      "{'title': '[花邊] Kerr談咖哩的走步：這種球以後都要吹', 'href': '/bbs/NBA/M.1669779886.A.EB9.html', 'push_count': 97, 'author': 'arod1414'}\n",
      "{'title': '[花邊] 裁判開始增加走步的吹判？', 'href': '/bbs/NBA/M.1669780805.A.856.html', 'push_count': 40, 'author': 'usnavyseal'}\n",
      "{'title': '[討論] 各隊打B2B隊伍慘血的場次數量', 'href': '/bbs/NBA/M.1669786254.A.AFD.html', 'push_count': 14, 'author': 'westley'}\n",
      "{'title': '[BOX ] Clippers 118:112 Blazers 數據', 'href': '/bbs/NBA/M.1669786501.A.D36.html', 'push_count': 61, 'author': 'Rambo'}\n",
      "{'title': '[花邊] Luka對裁判比\"愛心\"手勢', 'href': '/bbs/NBA/M.1669787897.A.865.html', 'push_count': 50, 'author': 'kevinwei223'}\n",
      "{'title': '[情報] 77談K湯壓哨出手：我沒有說謊，當時害怕極', 'href': '/bbs/NBA/M.1669790610.A.F8F.html', 'push_count': 50, 'author': 'arod1414'}\n",
      "{'title': '[情報] Markelle Fultz 即將回歸', 'href': '/bbs/NBA/M.1669744232.A.3EE.html', 'push_count': 65, 'author': 'Weasley40'}\n",
      "{'title': '[情報] Towns右小腿拉傷 將缺席4-6周', 'href': '/bbs/NBA/M.1669750580.A.8E2.html', 'push_count': 22, 'author': 'love1500274'}\n",
      "{'title': '[情報] 多名球員缺席今晚的快艇拓荒者之戰', 'href': '/bbs/NBA/M.1669760981.A.133.html', 'push_count': 64, 'author': 'EZ78'}\n",
      "{'title': '[情報] 裁判東尼兄弟辱罵丁丁被禁吹罰', 'href': '/bbs/NBA/M.1669764624.A.FCA.html', 'push_count': -10, 'author': 'scott6065'}\n",
      "{'title': '[Live] 尼克@活塞', 'href': '/bbs/NBA/M.1669765170.A.96D.html', 'push_count': 7, 'author': 'jerryyuan'}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    articles = web_scraping_bot(url)\n",
    "    for item in articles:\n",
    "        print(item)\n",
    "    popular_articles = popular_articles(articles)\n",
    "    save_to_json(popular_articles,'popular_articles.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
