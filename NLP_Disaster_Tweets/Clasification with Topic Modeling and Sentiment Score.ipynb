{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62211f72-c51f-4eee-930c-98a09a8e68e4",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this notebook, we use a new dataset, which includesthree new columns:\n",
    "1. sentiment_score and compound_sentiment are two kinds of sentiment score generated from text\n",
    "2. topic_list comes from topic modeling result. Each text is assigned with one topic, and we select the top5 words for that topic.\n",
    "\n",
    "We will use these two new features to see if they can improve our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6cf814-0273-4fe1-9522-dbfb9918d556",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28fab362-142c-41c7-9f77-59b2f1dd599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, f1_score,confusion_matrix\n",
    "from sklearn import feature_extraction\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dca4e5-cb94-4b2a-bd90-92624d841dd2",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd4febc2-e0f7-42ad-bab8-fb87874e95d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>target_relabelled</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>topic_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[\"releas\", \"trauma\", \"earthquak\", \"sever\", \"is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>[\"mh370\", \"get\", \"rain\", \"feel\", \"flood\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[\"siren\", \"tornado\", \"offic\", \"oil\", \"natur\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[\"disast\", \"wildfir\", \"fatal\", \"obama\", \"trap\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[\"wreck\", \"storm\", \"violent\", \"im\", \"like\"]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  target_relabelled  sentiment_score  compound_sentiment  \\\n",
       "0       1                  1            0.000                0.00   \n",
       "1       1                  1            0.000               -0.34   \n",
       "2       1                  1            0.000                0.00   \n",
       "3       1                  1            0.000                0.00   \n",
       "4       1                  1            0.125                0.00   \n",
       "\n",
       "                                          topic_list  \n",
       "0  [\"releas\", \"trauma\", \"earthquak\", \"sever\", \"is...  \n",
       "1          [\"mh370\", \"get\", \"rain\", \"feel\", \"flood\"]  \n",
       "2      [\"siren\", \"tornado\", \"offic\", \"oil\", \"natur\"]  \n",
       "3    [\"disast\", \"wildfir\", \"fatal\", \"obama\", \"trap\"]  \n",
       "4        [\"wreck\", \"storm\", \"violent\", \"im\", \"like\"]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "train_df = pd.read_excel(\"topic_model_sentiment.xlsx\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "347f1b6f-e3e4-4fe1-8898-bcad7c179f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#Last time we store list into topic_list and write to excel file. When it's read in, it can not be recognized as list. \n",
    "#Thus we need to first convert this topic_list column.\n",
    "print(type(train_df.iloc[0].topic_list))\n",
    "# Convert the text representation of the list to an actual list\n",
    "train_df['topic_list'] = train_df['topic_list'].apply(ast.literal_eval)\n",
    "print(type(train_df.iloc[0].topic_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "222e2ce3-aa35-4aa9-8fb2-314e46a1bbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>topic_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[releas, trauma, earthquak, sever, issu]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "\n",
       "   target  sentiment_score  compound_sentiment  \\\n",
       "0       1              0.0                 0.0   \n",
       "\n",
       "                                 topic_list  \n",
       "0  [releas, trauma, earthquak, sever, issu]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace target by target_relabelled\n",
    "train_df = train_df.drop('target', axis=1)\n",
    "column_mapping = {'target_relabelled': 'target'}\n",
    "train_df = train_df.rename(columns=column_mapping)\n",
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cf2252-d9f2-4023-a399-692dcafa6342",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3bee437-9f83-436f-a519-bc9318dae20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>topic_list</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_clean_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[releas, trauma, earthquak, sever, issu]</td>\n",
       "      <td>[deed, reason, earthquak, may, allah, forgiv, us]</td>\n",
       "      <td>deed reason earthquak may allah forgiv us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "\n",
       "   target  sentiment_score  compound_sentiment  \\\n",
       "0       1              0.0                 0.0   \n",
       "\n",
       "                                 topic_list  \\\n",
       "0  [releas, trauma, earthquak, sever, issu]   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  [deed, reason, earthquak, may, allah, forgiv, us]   \n",
       "\n",
       "                           text_clean_string  \n",
       "0  deed reason earthquak may allah forgiv us  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Preprocessing_for_Text_Processing_Comparison as pp\n",
    "train = pp.process_text(train_df)\n",
    "train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72e726b7-8236-4bf2-95a0-ae50b5a2efbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deed reason earthquak may allah forgiv us\n",
      "deed reason earthquak may allah forgiv us releas trauma earthquak sever issu\n"
     ]
    }
   ],
   "source": [
    "# Append words in topic_list to text_clean_string\n",
    "# Define a custom function to concatenate values \n",
    "def concatenate_values(row):\n",
    "    return row['text_clean_string'] + ' ' + ' '.join(row['topic_list'])\n",
    "\n",
    "# Apply the custom function to create column C\n",
    "train['combined_string'] = train.apply(concatenate_values, axis=1)\n",
    "print(train.iloc[0].text_clean_string)\n",
    "print(train.iloc[0].combined_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79499304-e4c6-4414-ae4b-81bc1b2db241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>topic_list</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_clean_string</th>\n",
       "      <th>combined_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[releas, trauma, earthquak, sever, issu]</td>\n",
       "      <td>[deed, reason, earthquak, may, allah, forgiv, us]</td>\n",
       "      <td>deed reason earthquak may allah forgiv us</td>\n",
       "      <td>deed reason earthquak may allah forgiv us rele...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "\n",
       "   target  sentiment_score  compound_sentiment  \\\n",
       "0       1              0.0                 0.0   \n",
       "\n",
       "                                 topic_list  \\\n",
       "0  [releas, trauma, earthquak, sever, issu]   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0  [deed, reason, earthquak, may, allah, forgiv, us]   \n",
       "\n",
       "                           text_clean_string  \\\n",
       "0  deed reason earthquak may allah forgiv us   \n",
       "\n",
       "                                     combined_string  \n",
       "0  deed reason earthquak may allah forgiv us rele...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9e4b38-560a-4e85-8d38-ff504ba2ae5f",
   "metadata": {},
   "source": [
    "### Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ead24325-10d6-4f02-a81a-de127d4c12ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9558550185873607\n",
      "F1 Score: 0.8038834951456311\n",
      "      0     1\n",
      "0  3843    42\n",
      "1   148  2057\n",
      "     0    1\n",
      "0  907   65\n",
      "1  137  414\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "train_vectors = count_vectorizer.fit_transform(train[\"text_clean_string\"])\n",
    "X = train_vectors\n",
    "y = train['target'].to_list()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "LR = LogisticRegression(solver='newton-cg')\n",
    "LR.fit(X_train,y_train)\n",
    "predicted = LR.predict(X_test)\n",
    "# print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "# print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted))\n",
    "# print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted))\n",
    "print(\"F1 Score:\",f1_score(y_train, LR.predict(X_train)))\n",
    "print(\"F1 Score:\",f1_score(y_test, predicted))\n",
    "# Confusion matrix\n",
    "print(pd.DataFrame(confusion_matrix(y_train, LR.predict(X_train))))\n",
    "print(pd.DataFrame(confusion_matrix(y_test, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5418db4-529e-4af1-93af-580f2c6a7446",
   "metadata": {},
   "source": [
    "### Word Frequency + Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cab4271a-7a50-4f79-b68c-8fa8b670808a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9563602599814298\n",
      "F1 Score: 0.8069835111542193\n",
      "      0     1\n",
      "0  3842    43\n",
      "1   145  2060\n",
      "     0    1\n",
      "0  908   64\n",
      "1  135  416\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "# Create your bag-of-words feature matrix\n",
    "train_vectors = count_vectorizer.fit_transform(train[\"text_clean_string\"])\n",
    "\n",
    "# Create your sentiment score feature (assumed as a 1D array)\n",
    "sentiment_score_column = train['compound_sentiment'].values.reshape(-1, 1)\n",
    "\n",
    "# Stack the bag-of-words and sentiment score horizontally\n",
    "X = hstack((train_vectors, sentiment_score_column))\n",
    "\n",
    "# Convert X to a dense array\n",
    "X = X.toarray()\n",
    "\n",
    "y = train['target'].to_list()\n",
    "\n",
    "# Split your data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train your logistic regression model\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predicted = LR.predict(X_test)\n",
    "print(\"F1 Score:\",f1_score(y_train, LR.predict(X_train)))\n",
    "print(\"F1 Score:\",f1_score(y_test, predicted))\n",
    "# Confusion matrix\n",
    "print(pd.DataFrame(confusion_matrix(y_train, LR.predict(X_train))))\n",
    "print(pd.DataFrame(confusion_matrix(y_test, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129a2aa8-43b7-4b47-b937-ddeee7daea2b",
   "metadata": {},
   "source": [
    "### Word Frequency + Topic List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "edb86ef3-c62f-4314-b466-a4b665eec484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9544186046511628\n",
      "F1 Score: 0.8096618357487922\n",
      "      0     1\n",
      "0  3842    43\n",
      "1   153  2052\n",
      "     0    1\n",
      "0  907   65\n",
      "1  132  419\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "train_vectors = count_vectorizer.fit_transform(train[\"combined_string\"])\n",
    "X = train_vectors\n",
    "y = train['target'].to_list()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "LR = LogisticRegression(solver='newton-cg')\n",
    "LR.fit(X_train,y_train)\n",
    "predicted = LR.predict(X_test)\n",
    "# print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "# print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted))\n",
    "# print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted))\n",
    "print(\"F1 Score:\",f1_score(y_train, LR.predict(X_train)))\n",
    "print(\"F1 Score:\",f1_score(y_test, predicted))\n",
    "# Confusion matrix\n",
    "print(pd.DataFrame(confusion_matrix(y_train, LR.predict(X_train))))\n",
    "print(pd.DataFrame(confusion_matrix(y_test, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3c1028-0468-416c-beb4-d7f255c267f6",
   "metadata": {},
   "source": [
    "### Word Frequency + Sentiment + Topic List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91ddc8b0-e644-42ae-9ab7-a3278793b75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9523809523809523\n",
      "F1 Score: 0.8088803088803088\n",
      "      0     1\n",
      "0  3835    50\n",
      "1   155  2050\n",
      "     0    1\n",
      "0  906   66\n",
      "1  132  419\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "# Create your bag-of-words feature matrix\n",
    "train_vectors = count_vectorizer.fit_transform(train[\"combined_string\"])\n",
    "\n",
    "# Create your sentiment score feature (assumed as a 1D array)\n",
    "sentiment_score_column = train['compound_sentiment'].values.reshape(-1, 1)\n",
    "\n",
    "# Stack the bag-of-words and sentiment score horizontally\n",
    "X = hstack((train_vectors, sentiment_score_column))\n",
    "\n",
    "# Convert X to a dense array\n",
    "X = X.toarray()\n",
    "\n",
    "y = train['target'].to_list()\n",
    "\n",
    "# Split your data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train your logistic regression model\n",
    "LR = LogisticRegression(solver='newton-cg')\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predicted = LR.predict(X_test)\n",
    "print(\"F1 Score:\",f1_score(y_train, LR.predict(X_train)))\n",
    "print(\"F1 Score:\",f1_score(y_test, predicted))\n",
    "# Confusion matrix\n",
    "print(pd.DataFrame(confusion_matrix(y_train, LR.predict(X_train))))\n",
    "print(pd.DataFrame(confusion_matrix(y_test, predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f88ec5-709c-456c-acd4-9469333d1eea",
   "metadata": {},
   "source": [
    "### Conclusion1:\n",
    "\n",
    "It seems like sentiment score and topic list don't help a lot with BOW model. All combinations get the similar F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1729586-9d4f-4b0f-84e8-8893adda9462",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e3050896-954d-4b65-987f-0a63d7ef9e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8442703232125367\n",
      "F1 Score: 0.7745197168857432\n",
      "      0     1\n",
      "0  3730   155\n",
      "1   481  1724\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>917</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>168</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  917   55\n",
       "1  168  383"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_text = TfidfVectorizer(min_df = 10, ngram_range = (1,2), stop_words='english') \n",
    "text_vec = vec_text.fit_transform(train['text_clean_string'])\n",
    "X_train_text = pd.DataFrame(text_vec.toarray(), columns=vec_text.get_feature_names_out())\n",
    "\n",
    "X = X_train_text\n",
    "y = train['target'].to_list()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train,y_train)\n",
    "predicted = LR.predict(X_test)\n",
    "# print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "# print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted))\n",
    "# print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted))\n",
    "print(\"F1 Score:\",f1_score(y_train, LR.predict(X_train)))\n",
    "print(\"F1 Score:\",f1_score(y_test, predicted))\n",
    "# Confusion matrix\n",
    "print(pd.DataFrame(confusion_matrix(y_train, LR.predict(X_train))))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a47f8-87fe-4d0f-a8cd-75d563cbb2e2",
   "metadata": {},
   "source": [
    "### TF-IDF + Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "247a4259-bbd2-40b8-a6c4-fadd9369c524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8478048780487805\n",
      "F1 Score: 0.7736040609137056\n",
      "      0     1\n",
      "0  3728   157\n",
      "1   467  1738\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>919</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  919   53\n",
       "1  170  381"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_text = TfidfVectorizer(min_df = 10, ngram_range = (1,2), stop_words='english') \n",
    "text_vec = vec_text.fit_transform(train['text_clean_string'])\n",
    "X_train_text = pd.DataFrame(text_vec.toarray(), columns=vec_text.get_feature_names_out())\n",
    "# Append sentiment score to TF-IDF \n",
    "X_train_text['sentiment'] = train['compound_sentiment']\n",
    "X = X_train_text\n",
    "y = train['target'].to_list()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train,y_train)\n",
    "predicted = LR.predict(X_test)\n",
    "# print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "# print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted))\n",
    "# print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted))\n",
    "print(\"F1 Score:\",f1_score(y_train, LR.predict(X_train)))\n",
    "print(\"F1 Score:\",f1_score(y_test, predicted))\n",
    "# Confusion matrix\n",
    "print(pd.DataFrame(confusion_matrix(y_train, LR.predict(X_train))))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf993629-c7fd-4c37-aef1-eb47e6e81144",
   "metadata": {},
   "source": [
    "### TF-IDF + Topic List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddb4f465-d60f-42e9-ab42-6ef7a34fad93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8227848101265822\n",
      "F1 Score: 0.7372881355932204\n",
      "      0     1\n",
      "0  3765   120\n",
      "1   580  1625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>927</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>203</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  927   45\n",
       "1  203  348"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_text = TfidfVectorizer(min_df = 10, ngram_range = (1,2), stop_words='english') \n",
    "text_vec = vec_text.fit_transform(train['combined_string'])\n",
    "X_train_text = pd.DataFrame(text_vec.toarray(), columns=vec_text.get_feature_names_out())\n",
    "\n",
    "X = X_train_text\n",
    "y = train['target'].to_list()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train,y_train)\n",
    "predicted = LR.predict(X_test)\n",
    "# print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "# print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted))\n",
    "# print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted))\n",
    "print(\"F1 Score:\",f1_score(y_train, LR.predict(X_train)))\n",
    "print(\"F1 Score:\",f1_score(y_test, predicted))\n",
    "# Confusion matrix\n",
    "print(pd.DataFrame(confusion_matrix(y_train, LR.predict(X_train))))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3786c3-0af1-4dbe-981f-ce2fa662f01f",
   "metadata": {},
   "source": [
    "### Word Frequency + Sentiment + Topic List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "27edce61-f7d4-49c3-b3bb-a06e77461b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8234410217881293\n",
      "F1 Score: 0.7533818938605619\n",
      "      0     1\n",
      "0  3741   144\n",
      "1   561  1644\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>924</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189</td>\n",
       "      <td>362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  924   48\n",
       "1  189  362"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_text = TfidfVectorizer(min_df = 10, ngram_range = (1,2), stop_words='english') \n",
    "text_vec = vec_text.fit_transform(train['combined_string'])\n",
    "X_train_text = pd.DataFrame(text_vec.toarray(), columns=vec_text.get_feature_names_out())\n",
    "# Append sentiment score to TF-IDF \n",
    "X_train_text['sentiment'] = train['compound_sentiment']\n",
    "X = X_train_text\n",
    "y = train['target'].to_list()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train,y_train)\n",
    "predicted = LR.predict(X_test)\n",
    "# print(\"Logistic Regression Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "# print(\"Logistic Regression Precision:\",metrics.precision_score(y_test, predicted))\n",
    "# print(\"Logistic Regression Recall:\",metrics.recall_score(y_test, predicted))\n",
    "print(\"F1 Score:\",f1_score(y_train, LR.predict(X_train)))\n",
    "print(\"F1 Score:\",f1_score(y_test, predicted))\n",
    "# Confusion matrix\n",
    "print(pd.DataFrame(confusion_matrix(y_train, LR.predict(X_train))))\n",
    "pd.DataFrame(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354ef6d1-bc3d-47a1-b1f7-a64116226360",
   "metadata": {},
   "source": [
    "### Conclusion2: \n",
    "\n",
    "Sentiment and topic list also don't help TF-IDF model. Topic list even decrease the F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adae97d-fa0a-46af-8186-7858f19bc336",
   "metadata": {},
   "source": [
    "### final Conlcusion\n",
    "\n",
    "1. BOW with Topic Modelling gives us the best F1 score: 0.809.\n",
    "2. From our experiment, we found that Sentiment and Topic Modelling don’t help the prediction a lot. It’s possible that the input matrixes of BOW and TF-IDF have high dimensions so Sentiment and Topic Modelling output can affect little.\n",
    "3. Logically Speaking, Sentence Embedding should give us best result. The reasons for this not occurring might result from there are still some mislabel data and we pass the embedding to simple classification model (logistic regression) instead of neural network.\n",
    "\n",
    "Further improvement will be focused on using LLM and NN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
