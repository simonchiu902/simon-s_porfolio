{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This web crawler is to compare different prices of a book on two different website (books.com and kingstone.com) to help customer to decide where to buy it. The title, ISBN, different prices of the book will be saved to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://search.books.com.tw/search/query/key/{0}/cat/all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_search_url(url, keyword):\n",
    "    url = url.format(keyword)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "user_agents = [\n",
    " \"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; AcooBrowser; .NET CLR 1.1.4322; .NET CLR 2.0.50727)\",\n",
    " \"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Acoo Browser; SLCC1; .NET CLR 2.0.50727; Media Center PC 5.0; .NET CLR 3.0.04506)\",\n",
    " \"Mozilla/4.0 (compatible; MSIE 7.0; AOL 9.5; AOLBuild 4337.35; Windows NT 5.1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)\",\n",
    " \"Mozilla/5.0 (Windows; U; MSIE 9.0; Windows NT 9.0; en-US)\",\n",
    " \"Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)\",\n",
    " \"Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.0.3705; .NET CLR 1.1.4322)\",\n",
    " \"Mozilla/4.0 (compatible; MSIE 7.0b; Windows NT 5.2; .NET CLR 1.1.4322; .NET CLR 2.0.50727; InfoPath.2; .NET CLR 3.0.04506.30)\",\n",
    " \"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/523.15 (KHTML, like Gecko, Safari/419.3) Arora/0.3 (Change: 287 c9dfb30)\",\n",
    " \"Mozilla/5.0 (X11; U; Linux; en-US) AppleWebKit/527+ (KHTML, like Gecko, Safari/419.3) Arora/0.6\",\n",
    " \"Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.2pre) Gecko/20070215 K-Ninja/2.1.1\",\n",
    " \"Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9) Gecko/20080705 Firefox/3.0 Kapiko/3.0\",\n",
    " \"Mozilla/5.0 (X11; Linux i686; U;) Gecko/20070322 Kazehakase/0.4.5\",\n",
    " \"Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.8) Gecko Fedora/1.9.0.8-1.fc10 Kazehakase/0.5.6\",\n",
    " \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.56 Safari/535.11\",\n",
    " \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/535.20 (KHTML, like Gecko) Chrome/19.0.1036.7 Safari/535.20\",\n",
    " \"Opera/9.80 (Macintosh; Intel Mac OS X 10.6.8; U; fr) Presto/2.9.168 Version/11.52\",\n",
    "    ]\n",
    "def get_resource(url):\n",
    "    headers = {\"user-agent\":random.choice(user_agents)}\n",
    "    return requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def parse_html(r):\n",
    "    if r.status_code == requests.codes.ok:\n",
    "        r.encoding = 'utf-8'\n",
    "        soup = BeautifulSoup(r.text,'lxml')\n",
    "    else:\n",
    "        print('error')\n",
    "        soup = None\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ISBN(url):\n",
    "    book_number = url.split('/')[10]\n",
    "    new_url = 'https://www.books.com.tw/products/{0}?sloc=main'.format(book_number)\n",
    "    soup = parse_html(get_resource(new_url))\n",
    "    if soup != None:\n",
    "        return soup.find(class_='mod_b type02_m058 clearfix').find('li').text[5:]\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_another_price(isbn):\n",
    "    url = 'https://www.kingstone.com.tw/search/key/'+isbn\n",
    "    soup = parse_html(get_resource(url))\n",
    "    # On kingstone website, if the isbn code cannot be found, it would give u several irrelavent books.\n",
    "    # Only when the buymixbox is unique, the kingstone website gives the correct book.\n",
    "    if len(soup.find_all(class_ = 'buymixbox')) == 1:\n",
    "        tag_div = soup.find(class_ = 'buymixbox')\n",
    "        price = tag_div.find_all('span')[1].b.text\n",
    "    else:\n",
    "        price=None\n",
    "    return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def web_scraping_bot(url):\n",
    "    booklist = []\n",
    "    soup = parse_html(get_resource(url))\n",
    "    if soup != None:\n",
    "        tag_table = soup.find_all(class_='table-td')\n",
    "        for item in tag_table:\n",
    "            book = []\n",
    "            book.append(item.find('img')['alt'])\n",
    "            isbn = get_ISBN(item.find('a')['href'])\n",
    "            book.append(isbn)\n",
    "            if len(item.find(class_='price clearfix').find_all('b')) == 1:\n",
    "                book.append(item.find(class_='price clearfix').find_all('b')[0].text)\n",
    "            else:\n",
    "                book.append(item.find(class_='price clearfix').find_all('b')[1].text)\n",
    "            price= get_another_price(isbn)\n",
    "            book.append(price)\n",
    "            booklist.append(book)\n",
    "            print('wait 10 seconds for next book...')\n",
    "            time.sleep(10) #the website block too intensive scrapping\n",
    "#             print(booklist)\n",
    "    return booklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def save_to_csv(booklist, file):\n",
    "    with open(file, 'w+', newline='') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        for book in booklist:\n",
    "            writer.writerow(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n",
      "wait 10 seconds for next book...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    url = generate_search_url(URL, 'machine learning')\n",
    "    booklist = web_scraping_bot(url)\n",
    "    save_to_csv(booklist, 'booklist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Machine Learning', '9789811519697', '3750', '3577'],\n",
       " ['Machine Learning', '9789811519666', '3750', None],\n",
       " ['Machine Learning', '9786203846447', '2155', '2419'],\n",
       " ['Machine Learning', '9781652126508', '315', None],\n",
       " ['Machine Learning', '9781107096394', '6300', None],\n",
       " ['Machine Learning', '9783902613561', '8055', '6927'],\n",
       " ['Machine Learning', '9780070428072', '20675', '19724'],\n",
       " ['Machine Learning', '9781558601482', '3648', None],\n",
       " ['Machine Learning', '9789533070339', '8055', '6927'],\n",
       " ['Python, Data Science and Machine Learning: From Scratch to Productivity',\n",
       "  '9789811215728',\n",
       "  '4900',\n",
       "  None],\n",
       " ['Financial Data Analytics with Machine Learning, Optimization and Statistics',\n",
       "  '9781119863373',\n",
       "  '2625',\n",
       "  None],\n",
       " ['Graph-Powered Analytics and Machine Learning with Tigergraph: Driving Business Outcomes with Connected Data',\n",
       "  '9781098106652',\n",
       "  '2100',\n",
       "  None],\n",
       " ['Advanced Analytics, Machine Learning, and AI in Biopharmaceutical Manufacturing Companies',\n",
       "  '9781119567509',\n",
       "  '16250',\n",
       "  None],\n",
       " ['Machine Learning for Wireless Communications and Networking: An Introduction',\n",
       "  '9780323912389',\n",
       "  '6250',\n",
       "  None],\n",
       " ['Earth Observation Applications to Landslide Mapping and Monitoring: Cutting-Edge Approaches with Machine Learning',\n",
       "  '9780128238684',\n",
       "  '8250',\n",
       "  None],\n",
       " ['Model-Based Machine Learning', '9781498756815', '4498', None],\n",
       " ['Applied Heath Care Analytics: Enabling Transformative Health Care Through Data Science, Machine Learning, and Cognitive',\n",
       "  '9789813142541',\n",
       "  '5750',\n",
       "  None],\n",
       " ['Resource-Efficient Artificial Intelligence: Probabilistic Machine Learning on Ultra-Low-Power Systems',\n",
       "  '9783110721058',\n",
       "  '3360',\n",
       "  None],\n",
       " ['Multimodal Biometric and Machine Learning Technologies: Applications for Computer Vision',\n",
       "  '9781119785408',\n",
       "  '10125',\n",
       "  None],\n",
       " ['Machine Learning for Biomedical Applications',\n",
       "  '9780128229040',\n",
       "  '3748',\n",
       "  None],\n",
       " ['The Art of Machine Learning', '9781718502109', '1750', None],\n",
       " ['Causal Analysis: Impact Evaluation and Causal Machine Learning with Applications in R',\n",
       "  '9780262545914',\n",
       "  '2000',\n",
       "  None],\n",
       " ['5g Technologies for Health Information System: A Machine Learning and Deep Learning Approach',\n",
       "  '9781119836186',\n",
       "  '11250',\n",
       "  None],\n",
       " ['Machine Learning for High-Risk Applications: Techniques for Responsible AI',\n",
       "  '9781098102432',\n",
       "  '2100',\n",
       "  None]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "booklist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
